# Problem : Automate the test cases on CAT for nioc version 3 [4264 m]
 #[Search tage = Error(),Problem(),SP]
# Goals :
 # nioc v3 test cases running in CAT 
 # transfer to CPD after automation
# Algorithm :
 # Terminology
 # Writing code for test cases (W)
 # Executing code for test cases (E)
 # Testcase - CAT integration (TC)
|--Cycle - W->E->TC
|--U : unknown
|------------------------------------
|-<SP#1> : Write one simple testcase "ResourcePoolSmallVmnics"
|--<Files>
|---vdnet/automation/VDNetLib/TestData/TestbedSpecs/TestbedSpec.pm
|---add one more vds to "OneHostNIOCv3VDS"
|---vdnet/automation/TDS/EsxServer/NetIORM/NetIOCv3Tds.pm
|--<Negative test case, no understanding of how vdnet processes negative test cases>
|---Is it worth spending time on this activity ?
|---No : Creation of negative test cases in automation framework is an external activity
|---Postponing this activity would be a better solution
|---Post a "TO_DO" comment in the TDS
|--<W : One positive test case [tc_chosen = 'DefaultVMStarving']>
|---Find a random test case that is not yet automated
|---Location : Inbox/Follow-up/action_items
|---Open up the document "NETIOCV3status-1.docx"
|---document's location in computer : "~/Documents/nioc_v3_automation/NETIOCV3status-1.docx"
|---Update the current status for 'ResourcePoolSmallVmnics"
|---tc_chosen = 'DefaultVMStarving'
|---<tc_understanding() [number_of_vms = 4]>
|----Verify impact on a default vm with no SLR on the same host where there are VMs with SLR
|----3 vms : vm.[1], vm.[2], vm.[3] => 1/3 of available bandwidth
|----SLR => Shares, Limits, Reservations
|----run_IO_Session(vms) || All the four vms
|----What does running IO session mean ?
|----One more test case that is automated might have IO session
|----tc = 'BasicScheduler'
|----tool_used = 'netperf'
|----parameters = [No_of_outbound = 1,SendMessageSize = 64512, LocalSendSocketSize = 131072, RemoteSendSocketSize = 131072,
|----              test_duration = 60]
|----Understand netperf
|----primary focus => bulk data transfer & request/response performance using either TCP/UDP
|----download netperf in windows 7 to see it in action
|----On running netperf.exe msg received = [establish control: are you sure there is a netserver listening on localhost
|                                           port 128657 establish_control could not establish the control connection from
|                                           0.0.0.0 port 0 address family AF_UNSPEC to localhost port 12865 address family
|                                           AF_UNSPEC]
|
|----postpone this activity
|--------------------------------------------------------------------------------------------------------------------------
|-<SP#2> => W:= "tc_creation(vm=1, run_IO_Session(vm.[1]), testbedspec = "oneHostNiocv3")
|--Use the reuse option already available since the testbed has already been saved
|--niocv3 alias caches the frequent access to te TDS "../TDS/EsxServer/NetIORM/NetIOCv3Tds.pm"
|--testbedspec field can be picked up from elsewhere using the search term "OneHost"
|--fill_up_workload_sequence(pick_workload_from_tc("BasicScheduler"))
|--compilation_error() {reason = "misplaced ] near the Sequence"}
|---------------------------------------------------------------------------------------------------------------------------
|--<SP#2.1> => Error() = "Node /testbed/host/1/vmknic/obj" does not exist"
|---The rootcause of the problem is that the testbedspec does not accomodate the required test inventory used in the tc
|---The impact of this problem was pretty huge emotionally because it affects the state of mind
|---come_back(state = "FEEL_GOOD") by writing down the solution [on paper/board/vim editor]
|---copy_testbed_spec(no_of_lines=84) from 'BasicScheduler' testcase
|---merge the spec with the available testbed spec and check if this works
|---same error was produced
|---problem_context = "run TCP traffic workload"
|---change the TCP traffic workload to contain vmnic 1 as support adapter instead of vmknic 1 and reuse the same testbed
|---------------------------------------------------------------------------------------------------------------------------
|---<SP#2.1.1> => Error() => [@VDNetLib::Workloads::TrafficWorkload:1704] [31694] Unable to either OS type  or Arch
|----First, get the latest git source
|----vm is powered off, this is the reason for this error
|----Power on both the vms and see if this works
|----retry() => error did not get resolved
|----problem_context() => re_run(tc='DefaultVMStarving')
|----Get the latest source available on git
|----I was able to get the latest source on master after I did a "git stash"
|----remove the commit from the master (Changes to Netioc TDS)
|----gitreset--hardHEAD^=>resetsthebranchtoHEADandremovesallcommits
|----merge stuff from one branch to another => git merge <branch> => merges changes made in <branch> into master
|----"git diff" to list all files that have conflicts
|----"git commit -a" will commit the result of the merge
|----"gitk" will show a graphical representation of the history
|----Get the latest changes from master onto the new branch "niocv3_automation"
|----git rebase master on "niocv3_automation" branch
|----git stash apply stash@{1} => replay the changes made on top of the branch
|----resulted in some conflicts
|----resolve_conflicts()
|----In this case, there is no need to resolve conflicts
|----Just add the file into the staged changes list
|----stash the changes when needed and reapply after rebasing to master
|----There was no controlIP in the netadapter object
|----Input tuple = "vm.[1].vnic.[1]"
|----controlIP = undef || macAddress = undef || vmOpsObj [vmIP => undef]
|----method = 'CreateNodes' || file = 'TrafficWorkload.pm'
|----inputs_to_method() || tuple = "vm.[1].vnic.[1]" || ref = <long_spec> || netobj = ref->[0]
|----when inserting print statements, it is good to use "$vdLogger" rather than print
|----ref : Array of objects || netobj : Object
|----who calls into "CreateNodes" ? => How about printing the entire method call hierarchy ?
|----Document the entire method hierarchy for this scenario
|----Ground rules => no computational lines / only subroutines
|----Format => Filename : Method_name()
|----entry_point => vdnet [shell script to be run on bash]
|----environment => ../main/environment
|----Perl entry_point  => ../main/vdNet.pl || $OPTION (a list of options to be passed)
|----Program starts here and terminates here
|----Store all cli parameters in $cliParams
|----Write a simple perl script that accepts a cli parameter and outputs the same
|----populate a parameter from the command line
|----store the parameter as a hash value in an object
|----store all relevant files under a folder named "f = practice_problem_1"
|----create a file called "entry_point.pl" which should contain the code for getting the options in
|----on mac perl version v5.16.3 => GetOptions always returns true whether the option was specified or not
|----The value "mine.yaml" was passed from command line and successfully stored in the hash which was printed via "Dumper" subroutine
|----Create a perl module named "Session.pm" => abstraction for a class
|----Create a hash cli_param inside the class
|----Create an object for Session inside the caller "entry_point.pl"
|----$session = VDNetLib::Session::Session->new('cliParams' => $cliParams); // Creating a new Session object
|----Run the session || $session->Run()
|----Cleanup the session || $session->Cleanup
|----Session->new() || Session->ConfigureLogging() || Utilities->GetLocalIP() || Session->ProcessAndValidateCLI()
|----SP => Setup a cron job for extending nimbus leases everyday 5:00 AM
|----sample => 0 5 |---- |---- |---- /path/to/command
|----as expected, only netfvt nimbus lease expiry email was received
|----need to test out a way if setting the cron job works
|----vc_ip = 10.114.166.197 || esx_ip = 10.115.174.115 || vm1_ip = 10.115.174.155 || vm2_ip = 10.115.174.156
|----save the vm ips in the yaml file and re-run the test case
|----If I specify 'ip' in the yaml file, is it good enough ?
|----Where is the code that processes 'vm' in the yaml file ?
|----Session.pm => ProcessAnValidateCLI()
|----$self->{userInputHash} => contains the hash that was defined in the yaml
|----$self->deployTestbed => calls ../scripts/deployTestbed.py
|----actual_action => VDNetLib/TestSession/VDNetv2.pm
|----put ip values for vm.[1] and vm.[2] and save the testbed
|----Error : VDNetLib::Common::Utilities [3012] => Failed to get 10.115.174.155 os type, staf running?
|----Check if staf service is running on esxi host
|----What is the command to check this ? => ps -P listed "STAFProc" => staf service was running on esxi host
|----re-try()
|----vm_ip(1,2) are not pingable from outside but the ip addresses on the second adapter are pingable from outside
|----add another network adapter on both the vms (check if new ip addresses are obtained on the adapters)
|----hot plug operation failed after wasting considerable amount of time
|----initiate a host reboot || host is not responding || remove from inventory
|----host is in a disconnected state || not_anymore
|----add_new_adapter() && remove_first_adapter()
|----vm_locations = [VM-1 => vdtest-26658/VM-1/RHEL|---- , VM-2 => vdtest-26663/VM-2/RHEL|----]
|----There was only one network interface in both the virtual machines but the ip addresses are pingable
|----current_problem() || proceed_with_one_interface()
|----hot_plug_operation_failed() => hot-add of ethernet adapter failed
|----instead of going after this problem, turn towards deploying another vm like tty
|----unregister_vms() => vim-cmd /vmsvc/unregister <vm_id>
|----delete_vmx_from_datastore() => rm -rf vdtest-|----
|----list all the vm templates in the inventory
|----./vdnet --listvms || choose tty_linux
|----save a testbed with the vms deployed on the esxi host (tty_linux)
|----Earlier, it fails at take snapshot step
|----switch vm to "RHEL63_srv_64_new" template
|----"tty_linux" deployment fails @ take_snapshot() step
|----staf error while retrieving vmx path on <esx_ip>
|----similar_bug = "bug |----1311733"
|----method => CreateLinkedClone() || File => HostOperations.pm
|----vmdk file here : /vmfs/volumes/vdnetSharedStorage/vdtest-8560/VM-1/|----.vmdk -> /vmfs/volumes/40c1109a-f631fa0e/RHEL63_srv_64_new/|----.vmdk
|----vmx file was not created => Did the linked clone operation start ?
|----modify the problem to deploy just one vm and comment out the "vc" portion || re_run()
|----vm_file_path = /vmfs/volumes/vdnetSharedStorage/vdtest-12915/VM-1/
|----Files_found = {3_vmdk, 1_vmsn, 1_vmsd, 1_vmx}
|----Problem => Unable to take a snapshot || "Invalid_snapshot_format"
|----last stack trace => VDNetLib::Testbed::Testbedv2::DeployVM
|----Search for CreateVM => 'grep -i -r CreateVM vdnet/automation/VDNetLib/|----'
|----Method => VMOpsTakeSnapshot || Error => "a required file was not found"
|----Create the linked clone for vm 'tty_linux' and register it in esxi host
|----register vm => vim-cmd /solo/registervm /vmfs/volumes/56106741-45556f9a/vdtest-12915/VM-1/tty4.vmx
|----create snapshot => vim-cmd /vmsvc/snapshot.create 16 delta-1 sample-snapshot true false
|----the operation failed
|----attempt to solve the problem of creating a linked clone of tty_linux vm in the following path : "/vmfs/volumes/vdnetSharedStorage/Sabesan/tty/|----"
|----HALT_FUNCTION()
|----Sequence :
|----Testbedv2::DeployVM()
|----Fetch the host object via "GetComponentObject" call (passing the hostIndex)
|----Invoke the "CreateVM" api call on the host object
|----HALT_FUNCTION()
|----It could be a storage array access issue
|----Create a local NFS share on ESXi box for the vm templates that you intend to use
|----what is your ESXi box ip ? => 10.33.75.228
|----HALT_FUNCTION()
|----Deploy required vms on the host in the testbed
|----$cmd_to_list_nfs_mounts_esxi = "esxcli storage nfs list"
|----remove(vdtest) : esxcli storage nfs remove -v vdtest
|----remove(vdnetSharedStorage) : esxcli storage nfs remove -v vdnetSharedStorage
|----remove(vdtest) => failed the second time
|----this_is_a_bug => cmd executes right the first time || same cmd fails the second time || QA = reliability
|----reboot_host() || retry() => able to remove the nfs share
|----run_testbed_deployment() : unable to remove vdtest (1) and mount vdtest
|----remove(vdtest (1)) & run_testbed_deployment() => FAIL
|----Error() = "Failed to find the given VM : rhel53-srv-32 under /vmfs/volumes/vdtest"
|----Problem() = "Addition of volume vdtest gets added as vdtest (1)"
|----solution() = "remove all mounts corresponding to host <prme-vmkqa-...storage-002-1...> and retry"
|----vm "rhel53-srv-32" has been deployed || $vm_ip = "10.115.174.132"
|---- HALT_FUNCTION()
|-----------------------------------------------------------------------------------------------------------------------------------------------------------
|-<SP#3> => W:= "tc_creation(vm=1, TCPTraffic(vm.[1]),testbedspec={})"
|--Error() = "[ERROR] - Node /testbed/vm/1/vnic/1/obj does not exist"
|--Root_Cause() = "vnic 1 of the vm is not registered as part of the testbed to be accesssed"
|--Problem() = "vnic_1 is not specified anywhere in the testbed spec that the test uses"
|--Solution() = "specify vnic_1 as part of the vm in the testbed save portion"
|--redeploy_vc(build = 2024545) || $cmd_vc = ". ~/public_html/scripts/deploy_vc.sh delta 2024545 2024545-nioc-vc-1"
|--$cmd_vc => !(worked) : VDNET && worked : DBC || Reason = POSTPONED
|--$vc_ip = "10.114.185.34"
|--Error() = "Neither of VM ip, vmx or template was provided"
   |--Root_Cause() = "vm.[2] was commented from the yaml file"
|--Error() = "[ERROR] - Failed to open YAML file /mts/home5/ssaidapetpach/yaml/netioc.yaml: YAML::XS::Load Error: The problem:
   |--did not find expected key
   |--was found at document: 1, line: 43, column: 6
   |--while parsing a block mapping at line: 2, column: 4
   |--$search_term = "yaml error did not find expected key"
   |--adjust_spaces() : uniform spacing between characters
   |--Root_Cause() = "indentation / spacing"
   |--Link = "https://www.ruby-forum.com/topic/4411986"
|--deploy_second_vm(vm.[2]) : =>  "on host host.[1]"
|--$vm_2_ip = "10.115.174.160"
|--encountered =>  Error():219
|--Error() = "[ERROR] - Failed to find VMX file for the VM IP: 10.115.174.160
   |--"[ERROR] - STDERR: Use of uninitialized value $tuple in concatenation (.) or string at "
      "/dbc/pa-dbc1109/ssaidapetpach/vdnet_git/src/nsx-qe/vdnet/automation/main/..//VDNetLib/Workloads/ParentWorkload.pm"
      "line 1348, <GEN13> line 148"
   |--cleanup_inventory() || "MANUAL"
   |--Location() = "[@VDNetLib::Host::HostOperations:18443]" ----> Error(){233}
   |--Method() = "GetVMX" ---> Location(){238} ---> Error(){233}
   |--$t_execute = 112 secs (setting up inventory / dc / vds / connect vms to vds)
   |--$cleanup_test() = "MANUAL"
   |--$output_print_statements =

     ----18393----inside the major if block
     ----18397---inside eth failure branch---
     ----18384----vmxFile = /vmfs/volumes/56106741-45556f9a/vdtest-16536/VM-1/rhel-53-srv-hw7-32-lsi-1gb-1cpu.vmx
     ----18393----inside the major if block
     "----18397---inside eth failure branch---" => leads to the root_cause{250}

   |--root_cause = VDNetLib::Common::Utilities::GetEthUnitNum($hostIP,$vmxFile, $mac);
   |--discard_changes("HostOperations.pm") => "git checkout -- vdnet/automation/VDNetLib/Host/HostOperations.pm"
   |--cleanup_inventory() || "MANUAL"
   |--Location() = "VDNetLib::Common::Utilities::GetEthUnitNum($hostIP,$vmxFile, $mac);"
   |--Method() = "GetEthUnitNum" || Parameters = {$hostIP,$vmxFile,$mac}
   |--$ops =

   ----2556--- Entry point ----10.115.174.115,/vmfs/volumes/56106741-45556f9a/vdtest-16536/VM-1/rhel-53-srv-hw7-32-lsi-1gb-1cpu.vmx,00:0C:29:C0:00:8C
   ----2596----grep -i 00:0C:29:C0:00:8C /vmfs/volumes/56106741-45556f9a/vdtest-16536/VM-1/rhel-53-srv-hw7-32-lsi-1gb-1cpu.vmx
   Code searches for "00:0C:29:C0:00:8C" in the vmx file and cannot be found

   |--root_cause = "mac address retrieved from ip address is different from the mac address published in vmx file"
   |--solution = "power cycle the vms"
|--vm_ip_list = {10.115.174.237,10.115.174.238}
|--cleanup_inventory() || "MANUAL"
|--Error() resulted because the new vm ips were not changed in the yaml file
|--cleanup_inventory() || "MANUAL"
|---------testbed_save_mode = PASS => M [Milestone]-------------------------
|--testbed_reuse_mode = FAIL
|--Location = /VDNetLib/Workloads/TrafficWorkload.pm line 1713 | Method = "CreateNodes" |
   Line : "my $mac = ($netObj->{intType} =~ /^vnic/i) ? $netObj->{macAddress} : $netObj->GetMACAddress();"
|--strategy => change the support adapter to point to the second vm's vnic
|--------problem_solved-------------M----------------------------------------
|--Error() = ping connectivity test failed
|--POST-MORTEM: Logs dir /tmp/vdnet/20140908-140157/1_TDS.EsxServer.NetIORM.NetIOCv3.DefaultVMStarving/traffic-20140908-140224/session-20140908-140224-834/
|--[root@prme-vmkqa-net3002-dhcp237 ~]|---- 
   
   ping -c 5 -I 192.168.174.237 172.17.166.137
   PING 172.17.166.137 (172.17.166.137) from 192.168.174.237 : 56(84) bytes of data.
   --- 172.17.166.137 ping statistics ---
   5 packets transmitted, 0 received, 100% packet loss, time 3999ms

|--------------------------------------------------------------------------------------------------------------
|--<SP#3.1> => Solve the problem of network connectivity between the network interfaces {264} 
|---Choose a physical adapter like vmnic2 which is not connected to any vswitch
|---It receives an ip address => 172.17.166.148
|---It is on the "172" subnet
|---<collab> : ssh_into_vm($cmd = "dhclient eth1") => got an ip on "172" subnet
|---The two interfaces are pingable on the network
|---------------------------------------------------------------------------------------------------------------
|--Data from TCPTraffic workload 
   
   client1's session throughput => ipv4 = 2244.74 mbps(tcp_stream)/2394.83 mbps(udp_stream)
                                   ipv6 = 1399.08 mbps(tcp_stream)/1786.16 mbps(udp_stream)	
|--<Files_to_be_visited>:
|---Folder => VDNetLib/Workloads/TrafficWorkload/ 
|---Files => [ArpPing,FragRoute,iperf,lighttpd,macoftool,mcast,netperf,nmap,ping,
              pptp,Session,SpirentAndPacketGenDesign,Spirent,TcpReplay,TrafficTool] 
|--Search for all possible traffic verification mechanisms in the existing tds
|--<Testcases_already_automated>
|--Format = <reservation>:<shares>:<limits>
|---sample_list = [VerifyResources => {change_rsl} 
                   VMUpgrade => {upgrade_hw_version,verify_placement}
                   InfraReservationLimits => {change_rsl,netperf}
                  ]
|--HALT_FUNCTION()
|--------------------------------------------------------------------------------------
|-<SP#4>: Document all the unknowns in the list of test cases that remain
|--------------------------------------------------------------------------------------
|--Duplicates = {55,61} 
|--<{1,2,6,9,10,11,17,18,27,28,29,31,71,50,52,53,54,60,64}>: (n=19)
|---(Risk = MAX | Procedure = TBD | Setup/test/test_verification = UNKNOWN)
|---setup_unknown(vxlan,sriov,vsan)
|---Unknowns = [9:configure QOS marking from src to dst ?
                9:QOS marked IO on vlan should be successful ?
                10:configure guest vlan tagging on src/dst vms ?
                10:QOS marked IO on guest vlan packets should be successful ?
                11:Perform (no) shutdown on switchport ?
                17:'LimitsVerifyAllSpeeds' => testcase description is very vague
                18:verify reservations are honored over shares ?
                27:set QOS to mark packets with a 802.1q tag ?
                27:continue setting values for 802.1p 0-7 ?
                28:continue setting values for DSCP 0-63 ?
                71:why was this ommitted from the document list ?
                50:what is meant by reload vmnic driver ? Can it be done within an automated testcase ?
                52:how do you enable stress option to simulate zero bandwidth ?<NOT_VALID>
                53:setup/test_procedure/verification/lacp ?
                54:interop_cdp_and_lldp similar to 53
                55:interop_sriov similar to 53
                60:interop_vcops : what stats are being exposed to vcops ? How can we get it via automation ?
                64:what is the limit on the number of resource pools ? <MANAGEMENT_PLANE>
                         
  	 
|--------------------------------------------------------------------------------------
|--<{4,5,7,8,12,14,15,16,23,24,26,32,35,46,47,49,51,57,59,62,63,65}>: (n=22)
|---(Risk = LOW | Procedure = known)
|---setup = (h-1(vm-1,vm-2), generate_vm_traffic(), generate_nfs_traffic())
|---Unknowns = [4:How do you generate nfs traffic io session ?,

                4:How do you verify that the nfs traffic got the right slr ?
                 - throughput = (esxtop => manual | vsi node)
                 - entitlement computation (first level => entitlement for infrastructure traffic)
                8:What is meant by "netflow packets should not be affected by NIOC" ?
                8:Should a separate netflow collector be configured for the interop with netflow ?
                14:vmotion to all older versions of ESXi 4.0,4.1,5.0,5.1,5.5 ? (how can this accomplished ?)
                24:why do we need 4 vms for this test case ?
                32:expected result TBD for slr configuration on pci passthru device ?    
               ]
|------------------------------------------------------------------------------------------------
|-<SP#5>: Attack testcase "4" => generating nfs traffic io session and verifying the throughput  
|------------------------------------------------------------------------------------------------
|--redeploy_vc(build = 2024545) || $cmd_vc = ". ~/public_html/scripts/deploy_vc.sh delta 2024545 2024545-nioc-vc-1"
|--vc_ip = 10.114.170.49
|--diskio => "vdnet/automatin/TDS/EsxServer/VSAN/CommonWorkloads.pm" => storageio related key
|--method => CreateIOSession => "vdnet/automation/VDNetLib/Root/Root.pm"
|--sample call to disk_io

   Type => "Root",
   TestNode => "root.[1]"
   diskio => {
      '[1]' => {
         toolname => "dt",
         testdisk => "vm.[1]",
         testduration => "120",
         operation => "startsession",
      },
|--vsan+netioc usecase is already present in vsan tds (remove from the netioc document)
|--vm_ip = [10.115.174.237,10.115.174.238]
|--insert "rundt" workload in the infratrafficnfs testcase
|--test_operation() || => failed to get vm ip address
|--HALT_FUNCTION()
|----------------------------------------------------------------------------------------
|-<SP#6>: Meeting notes on unknowns
|----------------------------------------------------------------------------------------
|--take care of putting existing test cases that are automated in CAT
|--<CHANGE_IN_APPROACH>:
   |--Put existing testcases that were already automated in CAT
   |--kill the existing inventory
   |--get all the vms in esx => "vim-cmd vmsvc/getallvms"
   |--"computeEntitlement" => 
|----------------------------------------------------------------------------------------
|-<SP#7>: upgrade_inventory() && recreate_setup()
|----------------------------------------------------------------------------------------
|--vsphere-2015-rel builds [ESXi = 2124407 || Cloud_vm = 2124880]
|--vc_ip = 10.114.169.144
|--upgrade_esxi() 
|--deploy_vms()
|-----------------------------------------------------------------------------------------
|-<SP#8>: Run the BasicScheduler testcase
|-----------------------------------------------------------------------------------------
|--vm_ips = [10.115.174.203, 10.115.174.205,10.115.174.204,10.115.174.207]
|--Error() = 

   |-- 2014-09-16 15:12:18.912 - [ERROR] - STDERR: Use of uninitialized value in string ne at /dbc/pa-dbc1109/ssaidapetpach/vdnet_git/src/nsx-qe/vdnet/automation/main/..
       //VDNetLib/Workloads/WorkloadsManager.pm line 767.Use of uninitialized value in concatenation (.) or string at 
       /dbc/pa-dbc1109/ssaidapetpach/vdnet_git/src/nsx-qe/vdnet/automation/main/..//VDNetLib/Workloads/WorkloadsManager.pm line 768.
       2014-09-16 15:12:36.913 - [ERROR] - Caught exception in child process whileexecuting TCPTraffic: Can't use string ("FAILURE") as a HASH ref while "strict refs" in use
       at /dbc/pa-dbc1109/ssaidapetpach/vdnet_git/src/nsx-qe/vdnet/automation/main/..//VDNetLib/Verification/NIOCVerification.pm line 510, <GEN3> line 233.
 
   |-- 2014-09-16 15:12:18.899 - [ERROR] - [@VDNetLib::Common::LocalAgent:191] [5485] Error while executing remote method GetPortEntitlement with args (vmnic3) on 10.115.174.115, Exit code:9 returned
       2014-09-16 15:12:18.912 - [ERROR] - [@VDNetLib::Common::LocalAgent:191] [5485] STDERR: Use of uninitialized value in string ne at
                                           /dbc/pa-dbc1109/ssaidapetpach/vdnet_git/src/nsx-qe/vdnet/automation/main/     ..//VDNetLib/Workloads/WorkloadsManager.pm line 767.
       Use of uninitialized value in concatenation (.) or string at /dbc/pa-dbc1109/ssaidapetpach/vdnet_git/src/nsx-qe/vdnet/automation/main/..//VDNetLib/Workloads/WorkloadsManager.pm line 768.
       2014-09-16 15:12:31.906 - [DEBUG] - [@VDNetLib::NetAdapter::Vnic::Vnic:2785] [5485] Executing command:vsish -pe get /net/portsets/DvsPortset-0/ports/50331658/niocVnicInfo
       2014-09-16 15:12:32.899 - [DEBUG] - [@VDNetLib::NetAdapter::Vnic::Vnic:2788] [5485] niocInfo:$VAR1 = {
           'rc' => 0,
           'stderr' => '',
           'exitCode' => '0',
           'stdout' => '{
           "uplinkDev" : "vmnic3",
           "reservation" : 100,
           "shares" : 50,
           "limit" : 1000,
           "worldID" : 41582,
           "vnicIndex" : 0,
           "tag" : 0,
           "niocVersion" : 3,
           "activeUplinks" : 1,
           "ppoolId" : "netsched.pools.persist.vm",
       }
       '
         };
      2014-09-16 15:12:35.898 - [DEBUG] - [@VDNetLib::NetAdapter::Vnic::Vnic:2846] [5485] GetNetSchedulerInfo command:vsish -pe get 
      /vmkModules/netsched/hclk/devs/vmnic3/qleaves/netsched.pools.vm.50331658/info
      2014-09-16 15:12:36.912 - [TRACE] - [@VDNetLib::Common::Iterator:879] [5485] Closed file handle of 
      /tmp/vdnet/20140916-150856/1_TDS.EsxServer.NetIORM.NetIOCv3.BasicScheduler/traffic-20140916-151122/IteratorCombo-20140916-151123-5485. Now deleting it...
      2014-09-16 15:12:36.912 - [DEBUG] - [@VDNetLib::Common::Iterator:889] [5485] Deleted Iterator's combination file: 
      /tmp/vdnet/20140916-150856/1_TDS.EsxServer.NetIORM.NetIOCv3.BasicScheduler/traffic-201409     16-151122/IteratorCombo-20140916-151123-5485
      2014-09-16 15:12:36.912 - [ERROR] - [@VDNetLib::Workloads::WorkloadsManager:614] [5485] Caught exception in child process whileexecuting TCPTraffic: 
      Can't use string ("FAILURE") as a HASH ref while "strict refs" in use at 
      /dbc/pa-dbc1109/ssaidapetpach/vdnet_git/src/nsx-qe/vdnet/automation/main/..//VDNetLib/Verification/NIOCVerification.pm line 510, <GEN3> line 233.

|--Log_location() = "/tmp/vdnet/20140916-150856/1_TDS.EsxServer.NetIORM.NetIOCv3.BasicScheduler/testcase.log"
|--Decomposition()
   |--Why is "vmnic3" being queried ? => all the vm vnics are on a vds portgroup whose pnic is "vmnic3"
   |--What is the first line where the error occurs ?
      -[@VDNetLib::Common::LocalAgent:191] [5485] Error while executing remote method GetPortEntitlement with args (vmnic3) on 10.115.174.115, Exit code:9 returned
   |--What was the call that resulted in this error ?
      -[@VDNetLib::Common::LocalAgent:171] [5485] Executing START SHELL COMMAND :34:/automation/scripts/remoteAgent.pl PARMS "-m GetPortEntitlement -p vmnic3"
   |--What is the corresponding subroutine that is linked in remoteAgent.pl ?
      -VDNetLib::Common::EsxUtils::GetPortEntitlement
   |--Restart STAF and check if this error is gone ?
      -STAF restarted with PID 10245 but this did not solve the problem
   |--sync_latest_code() && check() ?
      -"Problem_Not_Solved()"
   |--file_bug() => bug #1325365
   |--copy test_log to bug folder || "cp -r /tmp/vdnet/20140917-121600/ /bugs/files/0/1/3/2/5/3/6/5"
   |--flip the STAF library to a path that points to perl 5.10 => "ln -sf /build/toolchain/lin32/staf-3.4.1/lib/perl510/libPLSTAF.so /lib"
   |--Command to check if the staf call is working ? =>

      "/build/toolchain/lin32/staf-3.4.1/bin/STAF 10.115.174.115 process START SHELL COMMAND :34:/automation/scripts/remoteAgent.pl 
       PARMS "-m GetPortEntitlement -p vmnic3" RETURNSTDOUT STDERRTOSTDOUT WAIT 600000 ENV PARENT_SHARED_VAR=GetPortEntitlement-12-19-25-12042 
       ENV PARENT_SHARED_ERR=GetPortEntitlement-ERR-12-19-2512042 ENV VDNET_LOGLEVEL=9 ENV VDNET_LOGTOFILE=0 ENV VDNET_VERBOSE=1"

   |--problem isolated to vdnet_esx_setup.py
   |--retest() # with testbed reuse option, check if this works
   |--"PROBLEM_SOLVED"
|--<SP#8.1>: "git pushreview" failed with the following error :

          Total 0 (delta 0), reused 0 (delta 0)
          remote: Processing changes: refs: 1, done    
          To ssh://ssaidapetpach@gitreview.eng.vmware.com:29418/nsx-qe
          ! [remote rejected] HEAD -> refs/for/master (no new changes)
          error: failed to push some refs to 'ssh://ssaidapetpach@gitreview.eng.vmware.com:29418/nsx-qe'
   |--"post-review <commit-id>" posted the diff to a "reviewboard" url
   |--issue "git pushreview" now to get a url like "https://gitreview.eng.vmware.com:8443/7495"
   |--link => "https://sites.google.com/a/vmware.com/nsbu-engineering/home/engineering-process/getting-started-with-git-and-review-gerrit?pli=1"     
  
#[SP_7] : upgrade_inventory() && recreate_setup()
 # <Fill out the build numbers from RC builds>
 # vsphere-2015-rel builds [ESXi = <build> || Cloud_vm = <build>]
 # vc_ip = <ip>
 # upgrade_esxi() 
 # deploy_vms()

#[SP_8] : Putting a workload on CAT
 # link => https://wiki.eng.vmware.com/CAT  
 # Components of CAT => [UI,builder,controller,launcher]
 # builder => builds deliverables based on changesets that can be consumed (esx,cloudvm etc.)
 # tester => monitoring a test
 # host => prme-vmkqa-116 {10.115.174.116} 
 # machines_link => https://cat.eng.vmware.com/machine/machines/
 # no_esx_machines = 1830
 # prme-vmkqa-115 = https://nsx-cat.eng.vmware.com/machine/6038/ = tester 4846 (stopped state)
 # prme-vmkqa-116 = https://nsx-cat.eng.vmware.com/machine/6039/
 # NSX area = https://nsx-cat.eng.vmware.com/area/3016/ {2hr-production-not-visible} 
 # NSX tester = https://nsx-cat.eng.vmware.com/tester/3279/ {associated with prme-vmkqa-116} 
 # CAT views
  # production => monitoring product/branch stability
  # staging => monitoring new tests that would eventually go into production
  # experimental => monitoring any other tests
 # create a new area with slatype 2hr under experimental 
  # link => https://nsx-cat.eng.vmware.com/area/3740/
 # create a new workload and I would need the following details :
  # name => NETIOCV3-P0
  # launchhost => {base_esx_host = 10.33.75.228} || ip = 10.33.74.138 
  # executable => /build/trees/vdnet/main/automation/main/offsutVDNetWorkload.py --userconfig /mts/home5/ssaidapetpach/yaml/cat-netioc.yaml  
    #             --framework=vdnet --vdnetOptions "' --consoleLog 0 -t EsxServer.NetIORM.NetIOCv3.BasicScheduler '"
  # timeout => 72000
  # skipboot, visible (checked) && needsreboot (unchecked) 
  # there is an existing NSX workload
   # link => https://nsx-cat.eng.vmware.com/workload/8382/
  # creation_of_workunit() 
   # error while adding the workunit :
     # CAT Error 500 : ValidationError: [u'BuildDef validation error. Add a builder for the primary site: nsx.'] 
   # tester has been started => owner {ssaidapetpach} 
   # tester link => https://nsx-cat.eng.vmware.com/tester/3279/
  # swap nsx build with the stuff coming from management plane
 
#[SP_9] : workunit failed on CAT
  # link =>  

